{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d00a8595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.1.3-py3-none-any.whl (968 kB)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Collecting trio~=0.17\n",
      "  Downloading trio-0.20.0-py3-none-any.whl (359 kB)\n",
      "Collecting trio-websocket~=0.9\n",
      "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
      "Collecting sortedcontainers\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Collecting outcome\n",
      "  Downloading outcome-1.1.0-py2.py3-none-any.whl (9.7 kB)\n",
      "Requirement already satisfied: idna in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Collecting async-generator>=1.9\n",
      "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
      "Requirement already satisfied: sniffio in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Collecting wsproto>=0.14\n",
      "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
      "Collecting PySocks!=1.5.7,<2.0,>=1.5.6\n",
      "  Downloading PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Collecting cryptography>=1.3.4\n",
      "  Downloading cryptography-36.0.1-cp36-abi3-win_amd64.whl (2.2 MB)\n",
      "Collecting pyOpenSSL>=0.14\n",
      "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
      "Requirement already satisfied: certifi in c:\\users\\admin\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Collecting h11<1,>=0.9.0\n",
      "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: sortedcontainers, outcome, h11, cryptography, async-generator, wsproto, trio, PySocks, pyOpenSSL, trio-websocket, selenium\n",
      "Successfully installed PySocks-1.7.1 async-generator-1.10 cryptography-36.0.1 h11-0.13.0 outcome-1.1.0 pyOpenSSL-22.0.0 selenium-4.1.3 sortedcontainers-2.4.0 trio-0.20.0 trio-websocket-0.9.2 wsproto-1.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02201ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "Collecting beautifulsoup4\n",
      "  Downloading beautifulsoup4-4.10.0-py3-none-any.whl (97 kB)\n",
      "Collecting soupsieve>1.2\n",
      "  Downloading soupsieve-2.3.1-py3-none-any.whl (37 kB)\n",
      "Using legacy 'setup.py install' for bs4, since package 'wheel' is not installed.\n",
      "Installing collected packages: soupsieve, beautifulsoup4, bs4\n",
      "    Running setup.py install for bs4: started\n",
      "    Running setup.py install for bs4: finished with status 'done'\n",
      "Successfully installed beautifulsoup4-4.10.0 bs4-0.0.1 soupsieve-2.3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 21.2.3; however, version 22.0.4 is available.\n",
      "You should consider upgrading via the 'C:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python310\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f441d6dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish importing packages\n"
     ]
    }
   ],
   "source": [
    "# Import libraries and packages for the project \n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import csv\n",
    "print('- Finish importing packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62cdc0af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8960/928450213.py:3: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish initializing a driver\n"
     ]
    }
   ],
   "source": [
    "# Task 1.1: Open Chrome and Access Linkedin login site\n",
    "path='E:/Download/chromedriver_win32/chromedriver.exe'\n",
    "driver = webdriver.Chrome(path)\n",
    "sleep(2)\n",
    "url = 'https://www.linkedin.com/login'\n",
    "driver.get(url)\n",
    "print('- Finish initializing a driver')\n",
    "sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9488d328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish importing the login credentials\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8960/2902101160.py:8: DeprecationWarning: find_element_by_* commands are deprecated. Please use find_element() instead\n",
      "  email_field = driver.find_element_by_id('username')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish keying in email\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8960/2902101160.py:13: DeprecationWarning: find_element_by_name is deprecated. Please use find_element(by=By.NAME, value=name) instead\n",
      "  password_field = driver.find_element_by_name('session_password')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish keying in password\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8960/2902101160.py:19: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  signin_field = driver.find_element_by_xpath('//*[@id=\"organic-div\"]/form/div[3]/button')\n"
     ]
    }
   ],
   "source": [
    "credential = open('credentials.txt')\n",
    "line = credential.readlines()\n",
    "username = line[0]\n",
    "password = line[1]\n",
    "print('- Finish importing the login credentials')\n",
    "sleep(2)\n",
    "# Task 1.2: Key in login credentials\n",
    "email_field = driver.find_element_by_id('username')\n",
    "email_field.send_keys(username)\n",
    "print('- Finish keying in email')\n",
    "sleep(3)\n",
    "\n",
    "password_field = driver.find_element_by_name('session_password')\n",
    "password_field.send_keys(password)\n",
    "print('- Finish keying in password')\n",
    "sleep(2)\n",
    "\n",
    "# Task 1.2: Click the Login button\n",
    "signin_field = driver.find_element_by_xpath('//*[@id=\"organic-div\"]/form/div[3]/button')\n",
    "signin_field.click()\n",
    "sleep(3)\n",
    "\n",
    "print('- Finish Task 1: Login to Linkedin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e3d581",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8960/20798977.py:3: DeprecationWarning: find_element_by_xpath is deprecated. Please use find_element(by=By.XPATH, value=xpath) instead\n",
      "  search_field = driver.find_element_by_xpath('//*[@id=\"global-nav-typeahead\"]/input')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What type of key want to search Data engineer\n",
      "- Finish Task 2: Search for profiles\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Task 2: Search for the profile we want to crawl\n",
    "# Task 2.1: Locate the search bar element\n",
    "search_field = driver.find_element_by_xpath('//*[@id=\"global-nav-typeahead\"]/input')\n",
    "# //*[@id=\"global-nav-typeahead\"]/input\n",
    "\n",
    "# Task 2.2: Input the search query to the search bar\n",
    "search_query = input('What type of key want to search ')\n",
    "search_field.send_keys(search_query)\n",
    "\n",
    "# Task 2.3: Search\n",
    "search_field.send_keys(Keys.RETURN)\n",
    "\n",
    "print('- Finish Task 2: Search for profiles')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aeed0857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task 3: Scrape the URLs of the profiles\n",
    "# Task 3.1: Write a function to extract the URLs of one page\n",
    "def GetURL():\n",
    "    page_source = BeautifulSoup(driver.page_source)\n",
    "    profiles = page_source.find_all('a', class_ = 'app-aware-link') #('a', class_ = 'search-result__result-link ember-view')\n",
    "    all_profile_URL = []\n",
    "    for profile in profiles:\n",
    "        # profile_ID = profile.get('href')\n",
    "        # profile_URL = \"https://www.linkedin.com\" + profile_ID\n",
    "        profile_URL = profile.get('href')\n",
    "        if profile_URL not in all_profile_URL:\n",
    "            all_profile_URL.append(profile_URL)\n",
    "    return all_profile_URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fb11272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many pages you want to scrape: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp/ipykernel_8960/1475792147.py:9: DeprecationWarning: find_element_by_class_name is deprecated. Please use find_element(by=By.CLASS_NAME, value=name) instead\n",
      "  next_button = driver.find_element_by_class_name(\"artdeco-pagination__button--next\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Finish Task 3: Scrape the URLs\n"
     ]
    }
   ],
   "source": [
    "# Task 3.2: Navigate through many page, and extract the profile URLs of each page\n",
    "input_page = int(input('How many pages you want to scrape: '))\n",
    "URLs_all_page = []\n",
    "for page in range(input_page):\n",
    "    URLs_one_page = GetURL()\n",
    "    sleep(2)\n",
    "    driver.execute_script('window.scrollTo(0, document.body.scrollHeight);') #scroll to the end of the page\n",
    "    sleep(3)\n",
    "    next_button = driver.find_element_by_class_name(\"artdeco-pagination__button--next\")\n",
    "    driver.execute_script(\"arguments[0].click();\", next_button)\n",
    "    URLs_all_page = URLs_all_page + URLs_one_page\n",
    "    sleep(2)\n",
    "\n",
    "print('- Finish Task 3: Scrape the URLs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1b3a7e02",
   "metadata": {},
   "outputs": [
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=99.0.4844.51)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00FA9943+2595139]\n\tOrdinal0 [0x00F3C9F1+2148849]\n\tOrdinal0 [0x00E343F0+1065968]\n\tOrdinal0 [0x00E287C2+1017794]\n\tOrdinal0 [0x00E28FF8+1019896]\n\tOrdinal0 [0x00E2A892+1026194]\n\tOrdinal0 [0x00E24219+999961]\n\tOrdinal0 [0x00E35860+1071200]\n\tOrdinal0 [0x00E8B2D2+1422034]\n\tOrdinal0 [0x00E7B806+1357830]\n\tOrdinal0 [0x00E56086+1204358]\n\tOrdinal0 [0x00E56F96+1208214]\n\tGetHandleVerifier [0x0114B232+1658114]\n\tGetHandleVerifier [0x0120312C+2411516]\n\tGetHandleVerifier [0x0103F261+560433]\n\tGetHandleVerifier [0x0103E366+556598]\n\tOrdinal0 [0x00F4286B+2173035]\n\tOrdinal0 [0x00F475F8+2192888]\n\tOrdinal0 [0x00F476E5+2193125]\n\tOrdinal0 [0x00F511FC+2232828]\n\tBaseThreadInitThunk [0x760C6739+25]\n\tRtlGetFullPathName_UEx [0x773D8E7F+1215]\n\tRtlGetFullPathName_UEx [0x773D8E4D+1165]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_8960/2941590115.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriteheader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mlinkedin_URL\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mURLs_all_page\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlinkedin_URL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'- Accessing profile: '\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinkedin_URL\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# send output to comment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# random range\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, url)\u001b[0m\n\u001b[0;32m    435\u001b[0m         \u001b[0mLoads\u001b[0m \u001b[0ma\u001b[0m \u001b[0mweb\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcurrent\u001b[0m \u001b[0mbrowser\u001b[0m \u001b[0msession\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m         \"\"\"\n\u001b[1;32m--> 437\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGET\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'url'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    439\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=99.0.4844.51)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00FA9943+2595139]\n\tOrdinal0 [0x00F3C9F1+2148849]\n\tOrdinal0 [0x00E343F0+1065968]\n\tOrdinal0 [0x00E287C2+1017794]\n\tOrdinal0 [0x00E28FF8+1019896]\n\tOrdinal0 [0x00E2A892+1026194]\n\tOrdinal0 [0x00E24219+999961]\n\tOrdinal0 [0x00E35860+1071200]\n\tOrdinal0 [0x00E8B2D2+1422034]\n\tOrdinal0 [0x00E7B806+1357830]\n\tOrdinal0 [0x00E56086+1204358]\n\tOrdinal0 [0x00E56F96+1208214]\n\tGetHandleVerifier [0x0114B232+1658114]\n\tGetHandleVerifier [0x0120312C+2411516]\n\tGetHandleVerifier [0x0103F261+560433]\n\tGetHandleVerifier [0x0103E366+556598]\n\tOrdinal0 [0x00F4286B+2173035]\n\tOrdinal0 [0x00F475F8+2192888]\n\tOrdinal0 [0x00F476E5+2193125]\n\tOrdinal0 [0x00F511FC+2232828]\n\tBaseThreadInitThunk [0x760C6739+25]\n\tRtlGetFullPathName_UEx [0x773D8E7F+1215]\n\tRtlGetFullPathName_UEx [0x773D8E4D+1165]\n"
     ]
    }
   ],
   "source": [
    "import random # add sleeptime to scale system, and pass blocking by pass\n",
    "import pandas as pd\n",
    "# Task 4: Scrape the data of 1 Linkedin profile, and write the data to a .CSV file\n",
    "with open('output.csv', 'w',  newline = '') as file_output:\n",
    "    headers = ['Name', 'Job Title', 'Location', 'URL']\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for linkedin_URL in URLs_all_page:\n",
    "        driver.get(linkedin_URL)\n",
    "        print('- Accessing profile: ', linkedin_URL) # send output to comment \n",
    "        sleep(3) # random range\n",
    "        page_source = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        info_div = page_source.find('div',{'class':'flex-1 mr5'})\n",
    "        try:\n",
    "            name = info_div.find('li', class_='inline t-24 t-black t-normal break-words').get_text().strip() #Remove unnecessary characters \n",
    "            print('--- Profile name is: ', name)\n",
    "            location = info_div.find('li', class_='t-16 t-black t-normal inline-block').get_text().strip() #Remove unnecessary characters \n",
    "            print('--- Profile location is: ', location)\n",
    "            title = info_div.find('h2', class_='mt1 t-18 t-black t-normal break-words').get_text().strip()\n",
    "            print('--- Profile title is: ', title)\n",
    "            writer.writerow({headers[0]:name, headers[1]:location, headers[2]:title, headers[3]:linkedin_URL})\n",
    "            print('\\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print('Mission Completed!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97964e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv', 'w',  newline = '') as file_output:\n",
    "    headers = ['Name', 'Job Title', 'Location', 'URL']\n",
    "    writer = csv.DictWriter(file_output, delimiter=',', lineterminator='\\n',fieldnames=headers)\n",
    "    writer.writeheader()\n",
    "    for linkedin_URL in URLs_all_page:\n",
    "        driver.get(linkedin_URL)\n",
    "        print('- Accessing profile: ', linkedin_URL)\n",
    "        sleep(3)\n",
    "        page_source = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "        info_div = page_source.find('div',{'class':'flex-1 mr5'})\n",
    "        try:\n",
    "            name = info_div.find('li', class_='inline t-24 t-black t-normal break-words').get_text().strip() #Remove unnecessary characters \n",
    "            print('--- Profile name is: ', name)\n",
    "            location = info_div.find('li', class_='t-16 t-black t-normal inline-block').get_text().strip() #Remove unnecessary characters \n",
    "            print('--- Profile location is: ', location)\n",
    "            title = info_div.find('h2', class_='mt1 t-18 t-black t-normal break-words').get_text().strip()\n",
    "            print('--- Profile title is: ', title)\n",
    "            writer.writerow({headers[0]:name, headers[1]:location, headers[2]:title, headers[3]:linkedin_URL})\n",
    "            print('\\n')\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "print('Mission Completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
